import os
import sys
sys.path.append('../')
import unittest
import numpy as np
import tensorflow as tf
import sonnet as snt
import inspect

from config import Config
from tests.dummy_benchmark_generator import DummyTimeSeries, DummyBenchmarkGenerator
from utils.training_routine import training_routine_SimpleRNN, training_routine_RecGraphNet
from models.simple_rnn import *
from models.rec_graph_net import RecGraphNetwork
from models.graph_nets_deploy import *

"""
Config parameters to put inside the temp config files.
"""

CONFIG_SIMPLE_RNN = [20, 20, 1e-4, 1e-4, "n", 1]
CONFIG_REC_GRAPH_NET = [10, 10, 1e-4, 1e-4, "y", 2]

class TrainValTest(tf.test.TestCase):
    """
    Tensorflow-based base class for training and validation unittests.
    """
    def setUp(self):
        super(TrainValTest, self).setUp()
        tf.random.set_seed(1)

    def tearDown(self):
        pass

    def _benchmark(self):
        """
        Returns small GraphsTuple samples as a benchmark.
        """
        benchmark = DummyBenchmarkGenerator()
        return benchmark()

    def _create_config_file(self, name, ep_n, ep_e, l_n, l_e, model, pool_dim):
        """
        Creates temp config file for unittests. The file is deleted after
        a test run. Args are config file parameters.

        Args:
          - name: part of name of temp file;
          - ep_n: n. of epochs for node model;
          - ep_e: n. of epochs for edge model;
          - l_n: learning rate for node model;
          - l_e: learning rate for edge model;
          - model: either SimpleRNN (n) or RecGraphNetwork (y);
          - pool_dim: pool dimension for RecGraphNetwork reducer
            function.

        Returns:
          - filename: name of config file to be read by a Config object.
        """
        filename = f"{name}_temp.ini"
        content = f"[Epochs]\n" \
            f"ep_nodes = {ep_n}\n" \
            f"ep_edges = {ep_e}\n\n" \
            f"[Learning_rates]\n" \
            f"l_nodes = {l_n}\n" \
            f"l_edges = {l_e}\n\n" \
            f"[Model_options]\n" \
            f"graph_nets = {model}\n" \
            f"pool_dim = {pool_dim}"
        with open(os.path.join("config", filename), 'w') as f:
            f.write(content)
        return filename

    def _read_config(self, *args):
        """
        Reads the config file generated by self._create_config_file
        and returns the correspondig Config object.

        Args:
          - *args: the various arguments for self._create_config_file;

        Returns:
          - Config object of the config file;
          - config_file: name of the file.
        """
        config_file = self._create_config_file(*args)
        return Config(config_file), config_file

    def _model(self):
        """
        Returns the model to be trained/validated.
        """
        pass

    def _training_routine(self):
        """
        Returns the training routine relative to the tested model.
        """
        pass

    def test_training_routine(self, *args):
        """
        Tests the training routine at hand. The model objects generated
        are deleted at the end of testing.

        Args:
          - *args: arguments of training routine.
        """
        pass

    def _test_training(self):
        """
        Tests training function. The model objects generated
        are deleted at the end of testing.

        Returns:
          - save_model: name of saved model to be fed to self._test_validation.
        """
        pass

    def _test_validation(self, saved_model):
        """
        Tests validation function. The model objects generated
        are deleted at the end of testing.
        """
        pass

    def _test_train_val(self):
        """
        Tests function that trains and validates successively. The
        model objects generated are deleted at the end of testing.
        """
        pass

    def test_all(self):
        """
        Tests all the previous 3 functions successively. The model
        objects generated are deleted at the end of testing.
        """
        saved_model = self._test_training()
        self._test_validation(saved_model)
        self._test_train_val()


class SimpleRNNTrainValTest(TrainValTest):
    """
    Tensorflow-based unittest class for SimpleRNN's training and validation.
    """
    def _model(self):
        """
        Returns SimpleRNN to be trained/validated.
        """
        return SimpleRNN()

    def _training_routine(self, *args):
        """
        Returns the SimpleRNN training routine.

        Args:
          - *args: arguments of training routine.
        """
        return training_routine_SimpleRNN(*args)

    def test_training_routine(self, *args):
        """
        Tests the SimpleRNN training routine with a simple time series batch.
        The model objects generated are deleted at the end of testing.

        Args:
          - *args: arguments of training routine.
        """
        data = DummyTimeSeries()
        inputs, target = data()[:,:-1], data()[:,1:]
        model = self._model()
        loss = tf.losses.MeanSquaredError()
        self._training_routine(model, loss, 1e-4, 10, inputs, target, "N/A")

    def _test_training(self):
        """
        Tests training function through the generated benchmark. The model
        objects generated are then deleted at the end of self._test_validation.

        Returns:
          - save_model: name of saved model to be fed to self._test_validation.
        """
        config, _ = self._read_config("rnn", *CONFIG_SIMPLE_RNN)
        input_tr, target_tr = self._benchmark()
        input_vl, target_vl = self._benchmark()
        save_model = "test_rnn"
        train_rnn(input_tr, target_tr, input_vl, target_vl,
                        config, save_model, load_model=None)
        return save_model

    def _test_validation(self, save_model):
        """
        Tests validation function. The model objects generated
        are then deleted.

        Args:
          - save_model: name of models to load from files.
        """
        input_ts, target_ts = self._benchmark()
        validate_rnn(input_ts, target_ts, save_model, test=True)
        os.remove(os.path.join("saved_models", f"{save_model}_nodes.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_edges.obj"))

    def _test_train_val(self):
        """
        Tests function that trains and validates successively. The
        model objects generated are deleted before returning.
        """
        config, config_file = self._read_config("rnn", *CONFIG_SIMPLE_RNN)
        input_tr, target_tr = self._benchmark()
        input_vl, target_vl = self._benchmark()
        input_ts, target_ts = self._benchmark()
        data = [input_tr, target_tr, input_vl, target_vl, input_ts, target_ts]
        save_model = "test_rnn"
        train_test_rnn(config, save_model,
                         *data, test=True)
        os.remove(os.path.join("saved_models", f"{save_model}_nodes.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_edges.obj"))
        os.remove(os.path.join("config", config_file))


class RecGraphNetTrainValTest(TrainValTest):
    """
    Tensorflow-based unittest class for RecGraphNetwork's training and validation.
    """
    def _model(self, pool_dim):
        """
        Returns RecGraphNetwork to be trained/validated.
        """
        return RecGraphNetwork(pool_dim,
                None, None, None, None)

    def _training_routine(self, *args):
        """
        Returns the RecGraphNetwork training routine.

        Args:
          - *args: arguments of training routine.
        """
        return training_routine_RecGraphNet(*args)

    def test_training_routine(self, *args):
        """
        Tests the RecGraphNetwork training routine with the generated
        benchmark. The model objects generated are deleted at the end
        of testing.

        Args:
          - *args: arguments of training routine.
        """
        config, config_file = self._read_config("rgn", *CONFIG_REC_GRAPH_NET)
        inputs, target = self._benchmark()
        model = self._model(config.pool_dim)
        loss = tf.losses.MeanSquaredError()
        self._training_routine(model, loss, config.l_rate_nodes, config.l_rate_edges,
                            config.epochs_nodes, config.epochs_edges, inputs, target)
        os.remove(os.path.join("config", config_file))

    def _test_training(self):
        """
        Tests training function through the generated benchmark. The model
        objects generated are then deleted at the end of self._test_validation.

        Returns:
          - save_model: name of saved model to be fed to self._test_validation.
        """
        config, _ = self._read_config("rgn", *CONFIG_REC_GRAPH_NET)
        input_tr, target_tr = self._benchmark()
        input_vl, target_vl = self._benchmark()
        save_model = "test_rgn"
        train_graph_nets(input_tr, target_tr, input_vl, target_vl,
                            config, save_model, load_model=None)
        return save_model

    def _test_validation(self, save_model):
        """
        Tests validation function. The model objects generated
        are then deleted.

        Args:
          - save_model: name of models to load from files.
        """
        config, config_file = self._read_config("rgn", *CONFIG_REC_GRAPH_NET)
        input_ts, target_ts = self._benchmark()
        validate_graph_nets(input_ts, target_ts, config.pool_dim,
                                            save_model, test=True)
        os.remove(os.path.join("saved_models", f"{save_model}_nodes_rec.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_nodes_enc.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_edges_rec.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_edges_enc.obj"))
        os.remove(os.path.join("config", config_file))

    def _test_train_val(self):
        """
        Tests function that trains and validates successively. The
        model objects generated are deleted before returning.
        """
        config, config_file = self._read_config("rgn", *CONFIG_REC_GRAPH_NET)
        input_tr, target_tr = self._benchmark()
        input_vl, target_vl = self._benchmark()
        input_ts, target_ts = self._benchmark()
        data = [input_tr, target_tr, input_vl, target_vl, input_ts, target_ts]
        save_model = "test_model"
        train_test_graph_nets(config, save_model,
                         None, *data, test=True)
        os.remove(os.path.join("saved_models", f"{save_model}_nodes_rec.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_nodes_enc.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_edges_rec.obj"))
        os.remove(os.path.join("saved_models", f"{save_model}_edges_enc.obj"))
        os.remove(os.path.join("config", config_file))

